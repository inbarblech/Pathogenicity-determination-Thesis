{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T14:48:23.578811800Z",
     "start_time": "2024-05-05T14:48:23.559986200Z"
    }
   },
   "id": "cf2cecf95af5be29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "642a3492513f860a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\"\"\"Using this notebook, I will add \"\"\"\n",
    "\n",
    "# Change the genes!!! \n",
    "genes = []\n",
    "all_revel_files = pd.read_csv(\"C:\\\\Users\\\\InbarBlech\\\\PycharmProjects\\\\Thesis\\\\benchmarking\\\\REVEL\\\\all_REVEL_predictions.csv\")\n",
    "\n",
    "for gene in genes:\n",
    "    new_gene_path = f\"C:\\\\Users\\\\InbarBlech\\\\PycharmProjects\\\\Thesis\\\\benchmarking\\\\REVEL\\\\{gene}_revel_with_pos.csv\"\n",
    "    # read the file of the new gene\n",
    "    new_gene_predictions = pd.read_csv(new_gene_path)\n",
    "    # add \"gene\" column to the dataframe\n",
    "    new_gene_predictions[\"gene\"] = gene\n",
    "     \n",
    "    # add the new gene to the all_eve_files dataframe, without the header\n",
    "    all_revel_files = pd.concat([all_revel_files, new_gene_predictions], ignore_index=True, axis=0)\n",
    "\n",
    "# Save the new dataframe to a csv file\n",
    "all_revel_files.to_csv(\"C:\\\\Users\\\\InbarBlech\\\\PycharmProjects\\\\Thesis\\\\benchmarking\\\\REVEL\\\\all_REVEL_predictions.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:16:58.227076300Z",
     "start_time": "2023-11-23T14:16:57.707938200Z"
    }
   },
   "id": "a17f732a1c15f7f7"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Combine the prediction files into one file\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m my_prediction \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mInbarBlech\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mPycharmProjects\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mThesis\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpredictions_vs_real\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpredictions_vs_real_with_variant_all_genes_updated_221123.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m my_prediction\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine the prediction files into one file\n",
    "my_prediction = pd.read_csv(\"C:\\\\Users\\\\InbarBlech\\\\PycharmProjects\\\\Thesis\\\\predictions_vs_real\\\\predictions_vs_real_with_variant_all_genes_updated_221123.csv\")\n",
    "my_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T09:51:23.599191700Z",
     "start_time": "2024-05-02T09:51:23.267982600Z"
    }
   },
   "id": "62ba620050a56448"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "REVEL_predictions = pd.read_csv(\"C:\\\\Users\\\\InbarBlech\\\\PycharmProjects\\\\Thesis\\\\benchmarking\\\\REVEL\\\\all_REVEL_predictions.csv\")\n",
    "# Remove rows with gene null\n",
    "REVEL_predictions = REVEL_predictions[REVEL_predictions[\"gene\"].notnull()]\n",
    "REVEL_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T09:51:23.590192800Z"
    }
   },
   "id": "a0e2f72e1ea564c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Only leave \"wt_aa\", \"position\" \"mt_aa\" and \"EVE_scores_ASM\" columns\n",
    "REVEL_predictions = REVEL_predictions[['aa_wt', 'aa_mut', 'aa_pos', 'revel_score', 'gene']]\n",
    "REVEL_predictions[\"aa_pos\"] = REVEL_predictions[\"aa_pos\"].astype(str)\n",
    "# create new row \"variant\"\n",
    "REVEL_predictions['variant'] = REVEL_predictions['aa_wt'] + REVEL_predictions['aa_pos'] + REVEL_predictions['aa_mut']\n",
    "REVEL_predictions = REVEL_predictions.drop(columns=[\"aa_wt\", \"aa_mut\", \"aa_pos\"])\n",
    "REVEL_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T09:51:23.592191900Z"
    }
   },
   "id": "549962f614edb1c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"length of revel including VUS {len(REVEL_predictions)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T09:51:23.594191400Z"
    }
   },
   "id": "e7035f5e44d80982"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove VUS variants\n",
    "REVEL_predictions[\"revel_score\"] = pd.to_numeric(REVEL_predictions['revel_score'], errors='coerce')\n",
    "# Remove rows with revel score: 0.29 < revel score < 0.644\n",
    "REVEL_VUS = REVEL_predictions[(REVEL_predictions[\"revel_score\"] < 0.644) & (REVEL_predictions[\"revel_score\"] >= 0.29)]\n",
    "REVEL_predictions = REVEL_predictions[(REVEL_predictions[\"revel_score\"] >= 0.644) | (REVEL_predictions[\"revel_score\"] <= 0.29)]\n",
    "REVEL_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T09:51:23.596191Z"
    }
   },
   "id": "67966df88f2a0c48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add benign or pathogenic label to each variant, according to the VEST4 score\n",
    "REVEL_predictions[\"REVEL_pathogenicity\"] = REVEL_predictions[\"revel_score\"].apply(lambda x: 1 if x >= 0.644 else 0)\n",
    "REVEL_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T09:51:23.598191100Z"
    }
   },
   "id": "9124839f1149711c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save REVEL_predictions to csv\n",
    "REVEL_predictions.to_csv(\"C:\\\\Users\\\\InbarBlech\\\\PycharmProjects\\\\Thesis\\\\benchmarking\\\\REVEL\\\\REVEL_predictions_no_VUS.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T09:51:23.599191700Z"
    }
   },
   "id": "55bf2d2c61cadd79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"length of revel without VUS {len(REVEL_predictions)}\")\n",
    "print(f\"length of revel VUS {len(REVEL_VUS)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T09:51:23.661881600Z",
     "start_time": "2024-05-02T09:51:23.601192500Z"
    }
   },
   "id": "aec59bb6fdcab653"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge the two files\n",
    "merged = pd.merge(my_prediction, REVEL_predictions, on=[\"gene\", \"variant\"])\n",
    "merged"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T09:51:23.603192100Z"
    }
   },
   "id": "12b99d2bc029967a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To make sure that all tools will be tested on the same variants, save the merged with REVEL file and do so for all other tools. Then merge all the files together.\n",
    "merged_only_REVEL_columns = merged[['gene', 'variant', 'revel_score', 'REVEL_pathogenicity']]\n",
    "merged_only_REVEL_columns.to_csv(\"C:\\\\Users\\\\InbarBlech\\\\PycharmProjects\\\\Thesis\\\\benchmarking\\\\REVEL_on_dvd_data_predictions_LOPO.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T09:51:23.605192400Z"
    }
   },
   "id": "426678056b327e08"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "####################################################################################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T13:57:19.589130500Z",
     "start_time": "2023-11-14T13:57:19.573494Z"
    }
   },
   "id": "ef5069cb2a7928eb"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of merged 3016\n",
      "length of my_prediction 4521\n",
      "length of REVEL 36574\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of merged {len(merged)}\")\n",
    "print(f\"length of my_prediction {len(my_prediction)}\")\n",
    "print(f\"length of REVEL {len(REVEL_predictions)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T13:57:20.295074Z",
     "start_time": "2023-11-14T13:57:20.200867600Z"
    }
   },
   "id": "dd857b9172798518"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# All next rows were used to calculate the MCC, before realised I must apply first the threshold and remove the VUS variants. Now all these rows aren't in use, since I'm doing the calculations after removing the VUS variants and with all tools together.#############################################################################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a30e0709272d708"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ## Calculate the MCC for the mutpred predictions, according to the real pathogenicity (0 or 1)\n",
    "# from sklearn.metrics import matthews_corrcoef\n",
    "# \n",
    "# # separate the merged dataframe according to gene\n",
    "# genes = merged[\"gene\"].unique()\n",
    "# print(f\"Number of genes: {len(genes)}\")\n",
    "# # Calculate MCC for each gene specific predictor for EVE\n",
    "# \n",
    "# ### REVEL ####\n",
    "# \n",
    "# # Build dictionary with gene names as keys.\n",
    "# mccs = {gene: 0 for gene in genes}\n",
    "# \n",
    "# for gene in genes:\n",
    "#     gene_df = merged[merged[\"gene\"] == gene]\n",
    "#     gene_df['revel_score'] = gene_df['revel_score'].astype(float)\n",
    "#     # Assuming you have a DataFrame called 'data' with 'prediction' and 'MutPred_score' columns\n",
    "#     # Create binary predictions based on the 0.5 threshold\n",
    "#     gene_df.loc[:, 'binary_prediction_REVEL'] = (gene_df['revel_score'] > 0.644).astype(int)\n",
    "#     \n",
    "#     gene_df['predictions'] = gene_df['predictions'].astype(int)\n",
    "#     \n",
    "#     # Calculate MCC\n",
    "#     mcc = matthews_corrcoef(gene_df['predictions'], gene_df['binary_prediction_REVEL'])\n",
    "#     \n",
    "#     # Get gene name for the use for the dictionary\n",
    "#     gene = gene_df['gene'].unique()[0]\n",
    "#     \n",
    "#     # Append mcc to dictionary\n",
    "#     mccs[gene] = mcc\n",
    "# \n",
    "# print(\"MCCs of REVEL predictions for each gene:\")\n",
    "# for gene in mccs:\n",
    "#     print(f\"{gene}: {mccs[gene]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df090dadf6557863"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score, f1_score, \\\n",
    "#     log_loss, confusion_matrix\n",
    "# \n",
    "# # store the results in a dictionary\n",
    "# results = {gene: 0 for gene in genes}\n",
    "# \n",
    "# for gene in genes:\n",
    "#     gene_df = merged[merged[\"gene\"] == gene]\n",
    "#     gene_df['revel_score'] = gene_df['revel_score'].astype(float)\n",
    "#     y_true = gene_df[\"pathogenicity\"].astype(int)\n",
    "#     predicted_probabilities = gene_df[\"revel_score\"]\n",
    "#     gene_df.loc[:, 'binary_prediction_REVEL'] = (gene_df['revel_score'] > 0.644).astype(int)\n",
    "#     predicted_labels = gene_df[\"binary_prediction_REVEL\"]\n",
    "# \n",
    "#     results_gene = {}\n",
    "#     # Calculate AUC-ROC\n",
    "#     roc_auc = roc_auc_score(y_true, predicted_probabilities)\n",
    "#     # append to dictionary\n",
    "#     results_gene[\"roc_auc\"] = roc_auc\n",
    "# \n",
    "#     # Calculate ROC curve\n",
    "#     fpr, tpr, thresholds = roc_curve(y_true, predicted_probabilities)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     # append to dictionary\n",
    "#     results_gene[\"auc\"] = roc_auc\n",
    "# \n",
    "#     # Calculate AUC-PR\n",
    "#     precision, recall, _ = precision_recall_curve(y_true, predicted_probabilities)\n",
    "#     pr_auc = auc(recall, precision)\n",
    "#     # append to dictionary\n",
    "#     results_gene[\"pr_auc\"] = pr_auc\n",
    "# \n",
    "#     # Calculate F1 Score\n",
    "#     f1 = f1_score(y_true, predicted_labels)\n",
    "#     # append to dictionary\n",
    "#     results_gene[\"f1\"] = f1\n",
    "# \n",
    "#     # Calculate Log Loss\n",
    "#     logloss = log_loss(y_true, predicted_probabilities)\n",
    "#     # append to dictionary\n",
    "#     results_gene[\"logloss\"] = logloss\n",
    "# \n",
    "#     # Calculate confusion matrix\n",
    "#     conf_matrix = confusion_matrix(y_true, predicted_labels)\n",
    "#     # append to dictionary\n",
    "#     results_gene[\"confusion_matrix\"] = conf_matrix\n",
    "# \n",
    "#     # Get gene name for the use for the dictionary\n",
    "#     gene = gene_df['gene'].unique()[0]\n",
    "#     # Append results to dictionary\n",
    "#     results[gene] = results_gene\n",
    "# \n",
    "# ## Print results\n",
    "# print(\"Results of REVEL predictions for each gene:\")\n",
    "# for gene in results:\n",
    "#     print(f\"{gene}: {results[gene]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70a0e544deace7e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # present the confusion matrix for each gene\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# for gene in results:\n",
    "#     # Plot confusion matrix\n",
    "#     plt.imshow(results[gene][\"confusion_matrix\"], cmap=plt.cm.Blues)\n",
    "#     plt.xlabel(\"Predicted labels\")\n",
    "#     plt.ylabel(\"True labels\")\n",
    "#     plt.xticks([0, 1], [\"Benign\", \"Pathogenic\"])\n",
    "#     plt.yticks([0, 1], [\"Benign\", \"Pathogenic\"])\n",
    "#     plt.title(f\"Confusion matrix for {gene}, REVEL predictions\")\n",
    "#     plt.style.use(\"seaborn-white\")\n",
    "#     # Add text annotations\n",
    "#     for i in range(2):\n",
    "#         for j in range(2):\n",
    "#             plt.text(j, i, results[gene][\"confusion_matrix\"][i, j], ha=\"center\", va=\"center\", color=\"black\",\n",
    "#                      backgroundcolor=\"white\")\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17e816710c0a85e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # present the ROC curve for each gene\n",
    "# for gene in results:\n",
    "#     # Plot ROC curve\n",
    "#     plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area = {results[gene]['roc_auc']:.2f})\")\n",
    "#     plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel(\"False Positive Rate\")\n",
    "#     plt.ylabel(\"True Positive Rate\")\n",
    "#     plt.title(f\"ROC curve for {gene}, REVEL predictions\")\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e7bbefd1917d763"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
